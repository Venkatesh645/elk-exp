input {
  file {
    path => "/sample/log.log"
    start_position => "beginning"
    sincedb_path => "/dev/null"  # Ensures that the log file is read from the beginning every time (for testing purposes)
  }
}

filter {
  grok {
    match => { "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:loglevel}" }
  }

  date {
    match => [ "timestamp", "ISO8601" ]
    target => "@timestamp"
  }

  # Optionally, rename the 'timestamp' field to ensure it is indexed as a date
  mutate {
    rename => { "timestamp" => "log_timestamp" }
  }

  date {
    match => [ "log_timestamp", "ISO8601" ]
    target => "log_timestamp"
  }

}

output {
  # Output to Elasticsearch
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    # index => "logstash-%{+YYYY.MM.dd}"
    index => "logstash-app-logs"
    user => "elastic"
    password => "changeme"
  }

  # Output to standard output (console)
  stdout {
    codec => rubydebug
  }
}
